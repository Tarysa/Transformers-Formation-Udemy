{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5509e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "# import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d66cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api = KaggleApi()\n",
    "# api.authenticate\n",
    "# api.competition_download_file('sentiment-analysis-on-movie-reviews', 'test.tsv.zip', path='./')\n",
    "# api.competition_download_file('sentiment-analysis-on-movie-reviews', 'train.tsv.zip', path='./')\n",
    "\n",
    "# with zipfile.ZipFile('./train.tsv', 'r') as zipref:\n",
    "#     zipref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a03005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd1a1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df.drop_duplicates(subset = ['SentenceId'], keep='first')\n",
    "df[\"Sentiment\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74923657",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 512\n",
    "num_samples = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fbd3544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"Phrase\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf7f24e",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66880ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "256a0105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a20a8cef57b457cb9341411cc3d7c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "tokens = tokenizer(df[\"Phrase\"].tolist(), max_length = seq_len, truncation=True, padding = 'max_length',\n",
    "                add_special_tokens=True, return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89047a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d6d0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = df['Sentiment'].values\n",
    "labels = np.zeros((num_samples, arr.max()+1))\n",
    "labels[np.arange(num_samples), arr] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38445458",
   "metadata": {},
   "source": [
    "### Building dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9045a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3da5848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((tokens['input_ids'], tokens['attention_mask'] ,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5145e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(inputs_ids, masks, labels):\n",
    "    return {'input_ids' : inputs_ids, \n",
    "            'attention_mask' : masks}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "697c5d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(map_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f423e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da691a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.9\n",
    "size = int((tokens['input_ids'].shape[0] / batch_size) * split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24d1a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.take(size)\n",
    "val_ds = dataset.skip(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0593d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(train_ds, 'train')\n",
    "tf.data.experimental.save(val_ds, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3a6d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "element_spec = train_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b615e5",
   "metadata": {},
   "source": [
    "### Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0922b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92f41260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1730d5b8934df5b3777039cefd2802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39ad585f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c7398b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertMainLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertMainLayer object at 0x00000195BAF59910>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertMainLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertMainLayer object at 0x00000195BAF59910>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertEmbeddings.call of <transformers.models.bert.modeling_tf_bert.TFBertEmbeddings object at 0x00000195BCDA9310>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertEmbeddings.call of <transformers.models.bert.modeling_tf_bert.TFBertEmbeddings object at 0x00000195BCDA9310>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertEncoder.call of <transformers.models.bert.modeling_tf_bert.TFBertEncoder object at 0x00000195BB875640>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertEncoder.call of <transformers.models.bert.modeling_tf_bert.TFBertEncoder object at 0x00000195BB875640>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000195BB875250>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x00000195BB875250>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertAttention object at 0x00000195BB875A30>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertAttention object at 0x00000195BB875A30>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertSelfAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfAttention object at 0x00000195BB846730>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertSelfAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfAttention object at 0x00000195BB846730>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFBertPooler.call of <transformers.models.bert.modeling_tf_bert.TFBertPooler object at 0x00000195BB8759D0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertPooler.call of <transformers.models.bert.modeling_tf_bert.TFBertPooler object at 0x00000195BB8759D0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(512,), name = 'input_ids', dtype = 'int32')\n",
    "mask = tf.keras.layers.Input(shape=(512,), name = 'attention_mask', dtype = 'int32')\n",
    "\n",
    "#Bert embedding\n",
    "embeddings = bert.bert(input_ids, attention_mask = mask)[1]\n",
    "\n",
    "#Classifier for sentiment analysis\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
    "y = tf.keras.layers.Dense(5, activation='softmax', name= 'outputs')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91b90869",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d81861a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         787456      bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            5125        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 109,102,853\n",
      "Trainable params: 792,581\n",
      "Non-trainable params: 108,310,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69e54156",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=5e-5, decay=1e-6)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss = loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff6d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a6e82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.experimental.load('train', element_spec = element_spec)\n",
    "val_ds = tf.data.experimental.load('val', element_spec = element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fd8b1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  18/8778 [..............................] - ETA: 33:04:18 - loss: 1.3791 - accuracy: 0.5069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\thoma\\AppData\\Local\\Temp/ipykernel_11396/3692256294.py\", line 1, in <module>\n",
      "    history = model.fit(train_ds, shuffle=True, validation_data=val_ds, epochs=5)\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 108, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1098, in fit\n",
      "    tmp_logs = train_function(iterator)\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 780, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 807, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2829, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1843, in _filtered_call\n",
      "    return self._call_flat(\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1923, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 545, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\thoma\\Anaconda3\\envs\\Darmstadt\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11396/3692256294.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2060\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2063\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Darmstadt\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, shuffle=True, validation_data=val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f997a",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac3105",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Bert for Sentiment Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced5109",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6293cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(text):\n",
    "    tokens = tokenizer(text, max_length = 512, truncation=True, padding = 'max_length',\n",
    "                add_special_tokens=True, return_tensors='tf')\n",
    "    return {'input_ids' : tokens['input_ids'], 'attention_mask' : tokens['attention_mask']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d6ec834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03843514, 0.24493575, 0.44977775, 0.24813321, 0.01871812],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model.predict(prep_data('this movie was amazing'))[0]\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ad46af71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('test.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58a0e552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>156076</td>\n",
       "      <td>8546</td>\n",
       "      <td>Kidman is really the only thing that 's worth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>156154</td>\n",
       "      <td>8547</td>\n",
       "      <td>Once you get into its rhythm ... the movie bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>156178</td>\n",
       "      <td>8548</td>\n",
       "      <td>I kept wishing I was watching a documentary ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>156219</td>\n",
       "      <td>8549</td>\n",
       "      <td>Kinnear does n't aim for our sympathy , but ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PhraseId  SentenceId                                             Phrase\n",
       "0      156061        8545  An intermittently pleasing but mostly routine ...\n",
       "15     156076        8546  Kidman is really the only thing that 's worth ...\n",
       "93     156154        8547  Once you get into its rhythm ... the movie bec...\n",
       "117    156178        8548  I kept wishing I was watching a documentary ab...\n",
       "158    156219        8549  Kinnear does n't aim for our sympathy , but ra..."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['SentenceId'], keep='first')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e46f885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f13bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    tokens = prep_data(row['Phrase'])\n",
    "    probs = model.predict(tokens)\n",
    "    pred = np.argmax(probs)\n",
    "    df.at[i, 'Sentiment'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0405345",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
